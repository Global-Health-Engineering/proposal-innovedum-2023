@misc{2023what,
  title = {What {{Is Perplexity AI}}? {{A Deep Dive}} into {{AI}}'s {{Latest Phenomenon}} - {{AI For Folks}}},
  shorttitle = {What {{Is Perplexity AI}}?},
  year = {2023},
  month = aug,
  urldate = {2023-09-05},
  abstract = {And that's only one of the reasons why this text generator has become a popular favorite among many users already. So, what is Perplexity AI? In this blog},
  chapter = {Text AI},
  howpublished = {https://aiforfolks.com/what-is-perplexity-ai/},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/KLG7ZGJI/what-is-perplexity-ai.html}
}

@misc{becker2022programming,
  title = {Programming {{Is Hard}} -- {{Or}} at {{Least It Used}} to {{Be}}: {{Educational Opportunities And Challenges}} of {{AI Code Generation}}},
  shorttitle = {Programming {{Is Hard}} -- {{Or}} at {{Least It Used}} to {{Be}}},
  author = {Becker, Brett A. and Denny, Paul and {Finnie-Ansley}, James and {Luxton-Reilly}, Andrew and Prather, James and Santos, Eddie Antonio},
  year = {2022},
  month = dec,
  number = {arXiv:2212.01020},
  eprint = {2212.01020},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-08-31},
  abstract = {The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on how to overcome or otherwise mitigate the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Software Engineering,H.5.2,I.2,K.3.2},
  file = {/Users/lschoebitz/Zotero/storage/XVP3PCVY/Becker et al. - 2022 - Programming Is Hard -- Or at Least It Used to Be .pdf;/Users/lschoebitz/Zotero/storage/P8CW3W78/2212.html}
}

@misc{dellacqua2023navigating,
  type = {{{SSRN Scholarly Paper}}},
  title = {Navigating the {{Jagged Technological Frontier}}: {{Field Experimental Evidence}} of the {{Effects}} of {{AI}} on {{Knowledge Worker Productivity}} and {{Quality}}},
  shorttitle = {Navigating the {{Jagged Technological Frontier}}},
  author = {Dell'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R. and {Lifshitz-Assaf}, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, Fran{\c c}ois and Lakhani, Karim R.},
  year = {2023},
  month = sep,
  number = {4573321},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.4573321},
  urldate = {2023-09-20},
  abstract = {The public release of Large Language Models (LLMs) has sparked tremendous interest in how humans will use Artificial Intelligence (AI) to accomplish a variety of tasks. In our study conducted with Boston Consulting Group, a global management consulting firm, we examine the performance implications of AI on realistic, complex, and knowledge-intensive tasks. The pre-registered experiment involved 758 consultants comprising about 7\% of the individual contributor-level consultants at the company. After establishing a performance baseline on a similar task, subjects were randomly assigned to one of three conditions: no AI access, GPT-4 AI access, or GPT-4 AI access with a prompt engineering overview. We suggest that the capabilities of AI create a ``jagged technological frontier'' where some tasks are easily done by AI, while others, though seemingly similar in difficulty level, are outside the current capability of AI. For each one of a set of 18 realistic consulting tasks within the frontier of AI capabilities, consultants using AI were significantly more productive (they completed 12.2\% more tasks on average, and completed task  25.1\% more quickly), and produced significantly higher quality results (more than 40\% higher quality compared to a control group). Consultants across the skills distribution benefited significantly from having AI augmentation, with those below the average performance threshold increasing by 43\% and those above increasing by 17\% compared to their own scores. For a task selected to be outside the frontier, however, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI. Further, our analysis shows the emergence of two distinctive patterns of successful AI use by humans along a spectrum of human-AI integration. One set of consultants acted as ``Centaurs,'' like the mythical halfhorse/half-human creature, dividing and delegating their solution-creation activities to the AI or to themselves. Another set of consultants acted more like ``Cyborgs,'' completely integrating their task flow with the AI and continually interacting with the technology.},
  langid = {english},
  keywords = {Edward McFowland,Ethan R. Mollick,Fabrizio Dell'Acqua,Fran\c{c}ois Candelon,Hila Lifshitz-Assaf,Karim R. Lakhani,Katherine Kellogg,Lisa Krayer,Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality,Saran Rajendran,SSRN},
  file = {/Users/lschoebitz/Zotero/storage/U96WMPZF/Dell'Acqua et al. - 2023 - Navigating the Jagged Technological Frontier Fiel.pdf}
}

@misc{denny2023computing,
  title = {Computing {{Education}} in the {{Era}} of {{Generative AI}}},
  author = {Denny, Paul and Prather, James and Becker, Brett A. and {Finnie-Ansley}, James and Hellas, Arto and Leinonen, Juho and {Luxton-Reilly}, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
  year = {2023},
  month = jun,
  number = {arXiv:2306.02608},
  eprint = {2306.02608},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.02608},
  urldate = {2023-08-31},
  abstract = {The computing education community has a rich history of pedagogical innovation designed to support students in introductory courses, and to support teachers in facilitating student learning. Very recent advances in artificial intelligence have resulted in code generation models that can produce source code from natural language problem descriptions -- with impressive accuracy in many cases. The wide availability of these models and their ease of use has raised concerns about potential impacts on many aspects of society, including the future of computing education. In this paper, we discuss the challenges and opportunities such models present to computing educators, with a focus on introductory programming classrooms. We summarize the results of two recent articles, the first evaluating the performance of code generation models on typical introductory-level programming problems, and the second exploring the quality and novelty of learning resources generated by these models. We consider likely impacts of such models upon pedagogical practice in the context of the most recent advances at the time of writing.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  file = {/Users/lschoebitz/Zotero/storage/ZJP3H77C/Denny et al. - 2023 - Computing Education in the Era of Generative AI.pdf;/Users/lschoebitz/Zotero/storage/HYNA9FK3/2306.html}
}

@inproceedings{denny2023conversing,
  title = {Conversing with {{Copilot}}: {{Exploring Prompt Engineering}} for {{Solving CS1 Problems Using Natural Language}}},
  shorttitle = {Conversing with {{Copilot}}},
  booktitle = {Proceedings of the 54th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
  year = {2023},
  month = mar,
  series = {{{SIGCSE}} 2023},
  pages = {1136--1142},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3545945.3569823},
  urldate = {2023-09-05},
  abstract = {GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60\% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.},
  isbn = {978-1-4503-9431-4},
  keywords = {artificial intelligence,cs1,foundation models,github copilot,introductory programming,large language models,openai},
  file = {/Users/lschoebitz/Zotero/storage/R6T5PSCW/Denny et al. - 2023 - Conversing with Copilot Exploring Prompt Engineer.pdf}
}

@inproceedings{jonsson2022cracking,
  title = {Cracking the Code: {{Co-coding}} with {{AI}} in Creative Programming Education},
  shorttitle = {Cracking the Code},
  booktitle = {Creativity and {{Cognition}}},
  author = {Jonsson, Martin and Tholander, Jakob},
  year = {2022},
  month = jun,
  pages = {5--14},
  publisher = {{ACM}},
  address = {{Venice Italy}},
  doi = {10.1145/3527927.3532801},
  urldate = {2023-08-31},
  isbn = {978-1-4503-9327-0},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/62BT2LRL/Jonsson and Tholander - 2022 - Cracking the code Co-coding with AI in creative p.pdf}
}

@article{kaiss2023effectiveness,
  title = {Effectiveness of an {{Adaptive Learning Chatbot}} on {{Students}}' {{Learning Outcomes Based}} on {{Learning Styles}}},
  author = {Kaiss, Wijdane and Mansouri, Khalifa and Poirier, Franck},
  year = {2023},
  month = jul,
  journal = {International Journal of Emerging Technologies in Learning (iJET)},
  volume = {18},
  number = {13},
  pages = {250--261},
  issn = {1863-0383},
  doi = {10.3991/ijet.v18i13.39329},
  urldate = {2023-09-20},
  abstract = {Intelligent learning systems provide relevant learning materials to students based on their individual pedagogical needs and preferences. However, providing personalized learning objects based on learners' preferences, such as learning styles which are particularly important for the recommendation of learning objects, re-mains a challenge. Recommending the most appropriate learning objects for learners has always been a challenge in the field of e-learning. This challenge has driven educators and researchers to implement new ideas to help learners improve their learning experience and knowledge. New solutions use artificial intelligence (AI) techniques such as machine learning (ML) and natural language processing (NLP). In this paper, we propose and develop a new personalization approach for recommendation that implements the adaptation of learning objects according to the learners' learning style mainly focused on the use of a chatbot, named LearningPartnerBot, which will be integrated into the Moodle platform. We use the Felder-Silverman Learning Styles Model to determine learners' learning styles in order to recommend learning objects, and also to overcome the cold start problem. A chatbot is an automated communication tool that attempts to imitate a conversation by detecting the intentions of its user. The proposed LearningPartnerBot should be able to answer learners' questions in real time and provide a relevant set of suggestions according to their needs.},
  copyright = {Copyright (c) 2023 Wijdane KAISS, Khalifa  Mansouri, Franck Poirier},
  langid = {english},
  keywords = {Moodle},
  file = {/Users/lschoebitz/Zotero/storage/DKA7BTA7/Kaiss et al. - 2023 - Effectiveness of an Adaptive Learning Chatbot on S.pdf}
}

@article{kasneci2023chatgpt,
  title = {{{ChatGPT}} for Good? {{On}} Opportunities and Challenges of Large Language Models for Education},
  shorttitle = {{{ChatGPT}} for Good?},
  author = {Kasneci, Enkelejda and Sessler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and G{\"u}nnemann, Stephan and H{\"u}llermeier, Eyke and Krusche, Stephan and Kutyniok, Gitta and Michaeli, Tilman and Nerdel, Claudia and Pfeffer, J{\"u}rgen and Poquet, Oleksandra and Sailer, Michael and Schmidt, Albrecht and Seidel, Tina and Stadler, Matthias and Weller, Jochen and Kuhn, Jochen and Kasneci, Gjergji},
  year = {2023},
  month = apr,
  journal = {Learning and Individual Differences},
  volume = {103},
  pages = {102274},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2023.102274},
  urldate = {2023-08-31},
  abstract = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.},
  keywords = {Artificial intelligence,Education,Educational technologies,Large language models},
  file = {/Users/lschoebitz/Zotero/storage/R84L6X5H/Kasneci et al. - 2023 - ChatGPT for good On opportunities and challenges .pdf;/Users/lschoebitz/Zotero/storage/D7HPUBVK/S1041608023000195.html}
}

@inproceedings{kazemitabaar2023studying,
  title = {Studying the Effect of {{AI Code Generators}} on {{Supporting Novice Learners}} in {{Introductory Programming}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
  year = {2023},
  month = apr,
  eprint = {2302.07427},
  primaryclass = {cs},
  pages = {1--23},
  doi = {10.1145/3544548.3580919},
  urldate = {2023-08-31},
  abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/lschoebitz/Zotero/storage/EHV6ID4R/Kazemitabaar et al. - 2023 - Studying the effect of AI Code Generators on Suppo.pdf;/Users/lschoebitz/Zotero/storage/4DFBFZEX/2302.html}
}

@misc{kiesler2023large,
  title = {Large {{Language Models}} in {{Introductory Programming Education}}: {{ChatGPT}}'s {{Performance}} and {{Implications}} for {{Assessments}}},
  shorttitle = {Large {{Language Models}} in {{Introductory Programming Education}}},
  author = {Kiesler, Natalie and Schiffner, Daniel},
  year = {2023},
  month = aug,
  number = {arXiv:2308.08572},
  eprint = {2308.08572},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.08572},
  urldate = {2023-08-31},
  abstract = {This paper investigates the performance of the Large Language Models (LLMs) ChatGPT-3.5 and GPT-4 in solving introductory programming tasks. Based on the performance, implications for didactic scenarios and assessment formats utilizing LLMs are derived. For the analysis, 72 Python tasks for novice programmers were selected from the free site CodingBat. Full task descriptions were used as input to the LLMs, while the generated replies were evaluated using CodingBat's unit tests. In addition, the general availability of textual explanations and program code was analyzed. The results show high scores of 94.4 to 95.8\% correct responses and reliable availability of textual explanations and program code, which opens new ways to incorporate LLMs into programming education and assessment.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Software Engineering},
  file = {/Users/lschoebitz/Zotero/storage/ZWFBLNBE/Kiesler and Schiffner - 2023 - Large Language Models in Introductory Programming .pdf;/Users/lschoebitz/Zotero/storage/MF3DVZ3X/2308.html}
}

@misc{liang2023understanding,
  title = {Understanding the {{Usability}} of {{AI Programming Assistants}}},
  author = {Liang, Jenny T. and Yang, Chenyang and Myers, Brad A.},
  year = {2023},
  month = mar,
  number = {arXiv:2303.17125},
  eprint = {2303.17125},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-05},
  abstract = {The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output. Our findings have implications for both creators and users of AI programming assistants, such as designing minimal cognitive effort interactions with these tools to reduce distractions for users while they are programming.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Software Engineering},
  file = {/Users/lschoebitz/Zotero/storage/E5WGRREG/Liang et al. - 2023 - Understanding the Usability of AI Programming Assi.pdf;/Users/lschoebitz/Zotero/storage/QY25ZBAZ/2303.html}
}

@misc{liffiton2023codehelp,
  title = {{{CodeHelp}}: {{Using Large Language Models}} with {{Guardrails}} for {{Scalable Support}} in {{Programming Classes}}},
  shorttitle = {{{CodeHelp}}},
  author = {Liffiton, Mark and Sheese, Brad and Savelka, Jaromir and Denny, Paul},
  year = {2023},
  month = aug,
  number = {arXiv:2308.06921},
  eprint = {2308.06921},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.06921},
  urldate = {2023-08-31},
  abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students' usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/lschoebitz/Zotero/storage/Z65N4IT4/Liffiton et al. - 2023 - CodeHelp Using Large Language Models with Guardra.pdf;/Users/lschoebitz/Zotero/storage/DIX32YPR/2308.html}
}

@misc{mollick2023assigning,
  type = {{{SSRN Scholarly Paper}}},
  title = {Assigning {{AI}}: {{Seven Approaches}} for {{Students}}, with {{Prompts}}},
  shorttitle = {Assigning {{AI}}},
  author = {Mollick, Ethan R. and Mollick, Lilach},
  year = {2023},
  month = jun,
  number = {4475995},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.4475995},
  urldate = {2023-08-30},
  abstract = {This paper examines the transformative role of Large Language Models (LLMs) in education and their potential as learning tools, despite their inherent risks and limitations. The authors propose seven approaches for utilizing AI in classrooms: AI-tutor, AI-coach, AI-mentor, AI-teammate, AI-tool, AI-simulator, and AI-student, each with distinct pedagogical benefits and risks. The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases. These strategies promote active oversight, critical assessment of AI outputs, and complementarity of AI's capabilities with the students' unique insights. By challenging students to remain the "human in the loop", the authors aim to enhance learning outcomes while ensuring that AI serves as a supportive tool rather than a replacement. The proposed framework offers a guide for educators navigating the integration of AI-assisted learning in classrooms.},
  langid = {english},
  keywords = {AI,Education,LLM,Prompts},
  file = {/Users/lschoebitz/Zotero/storage/8ZP8XAFM/Mollick and Mollick - 2023 - Assigning AI Seven Approaches for Students, with .pdf}
}

@misc{mollick2023how,
  title = {How to {{Use AI}} to {{Do Stuff}}: {{An Opinionated Guide}}},
  shorttitle = {How to {{Use AI}} to {{Do Stuff}}},
  author = {Mollick, Ethan},
  year = {2023},
  month = mar,
  urldate = {2023-08-30},
  abstract = {Covering the state of play as of Summer, 2023},
  howpublished = {https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/DTPD7BFZ/how-to-use-ai-to-do-stuff-an-opinionated.html}
}

@misc{mollick2023now,
  title = {Now Is the Time for Grimoires},
  author = {Mollick, Ethan},
  year = {2023},
  month = jul,
  urldate = {2023-08-30},
  abstract = {It isn't data that will unlock AI, it is human expertise},
  howpublished = {https://www.oneusefulthing.org/p/now-is-the-time-for-grimoires},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/2ESUQF8H/now-is-the-time-for-grimoires.html}
}

@misc{mollick2023using,
  type = {{{SSRN Scholarly Paper}}},
  title = {Using {{AI}} to {{Implement Effective Teaching Strategies}} in {{Classrooms}}: {{Five Strategies}}, {{Including Prompts}}},
  shorttitle = {Using {{AI}} to {{Implement Effective Teaching Strategies}} in {{Classrooms}}},
  author = {Mollick, Ethan R. and Mollick, Lilach},
  year = {2023},
  month = mar,
  number = {4391243},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.4391243},
  urldate = {2023-08-31},
  abstract = {This paper provides guidance for using AI to quickly and easily implement evidence-based teaching strategies that instructors can integrate into their teaching. We discuss five teaching strategies that have proven value but are hard to implement in practice due to time and effort constraints. We show how AI can help instructors create material that supports these strategies and improve student learning. The strategies include providing multiple examples and explanations; uncovering and addressing student misconceptions; frequent low-stakes testing; assessing student learning; and distributed practice. The paper provides guidelines for how AI can support each strategy, and discusses both the promises and perils of this approach, arguing that AI may act as a ``force multiplier'' for instructors if implemented cautiously and thoughtfully in service of evidence-based teaching practices.},
  langid = {english},
  keywords = {AI,ChatGPT,GPT4,Learning},
  file = {/Users/lschoebitz/Zotero/storage/KCTBVZHH/Mollick and Mollick - 2023 - Using AI to Implement Effective Teaching Strategie.pdf}
}

@misc{mollick2023what,
  title = {What {{AI}} Can Do with a Toolbox... {{Getting}} Started with {{Code Interpreter}}},
  author = {Mollick, Ethan},
  year = {2023},
  month = jul,
  urldate = {2023-08-30},
  abstract = {Democratizing data analysis with AI},
  howpublished = {https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting?utm\_medium=reader2},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/EDGGHGBA/what-ai-can-do-with-a-toolbox-getting.html}
}

@misc{post,
  title = {Post | {{Feed}} | {{LinkedIn}}},
  urldate = {2023-09-14},
  howpublished = {https://www.linkedin.com/feed/update/urn:li:activity:7099179288150622209/},
  file = {/Users/lschoebitz/Zotero/storage/8MXVWZCW/urnliactivity7099179288150622209.html}
}

@misc{prather2023it,
  title = {"{{It}}'s {{Weird That}} It {{Knows What I Want}}": {{Usability}} and {{Interactions}} with {{Copilot}} for {{Novice Programmers}}},
  shorttitle = {"{{It}}'s {{Weird That}} It {{Knows What I Want}}"},
  author = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and {Luxton-Reilly}, Andrew and Powell, Garrett and {Finnie-Ansley}, James and Santos, Eddie Antonio},
  year = {2023},
  month = apr,
  number = {arXiv:2304.02491},
  eprint = {2304.02491},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-05},
  abstract = {Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction},
  file = {/Users/lschoebitz/Zotero/storage/D75CBJLW/Prather et al. - 2023 - It's Weird That it Knows What I Want Usability .pdf;/Users/lschoebitz/Zotero/storage/C6ZWBD85/2304.html}
}

@article{rudolph2023chatgpt,
  title = {{{ChatGPT}}: {{Bullshit}} Spewer or the End of Traditional Assessments in Higher Education?},
  shorttitle = {{{ChatGPT}}},
  author = {Rudolph, J{\"u}rgen and Tan, Samson and Tan, Shannon},
  year = {2023},
  month = jan,
  journal = {Journal of Applied Learning and Teaching},
  volume = {6},
  number = {1},
  pages = {342--363},
  issn = {2591-801X},
  doi = {10.37074/jalt.2023.6.1.9},
  urldate = {2023-09-05},
  abstract = {ChatGPT is the world's most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI's Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT's functionality and a summary of its strengths and limitations, we focus on the technology's implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.},
  copyright = {Copyright (c) 2023 Journal of Applied Learning and Teaching},
  langid = {english},
  file = {/Users/lschoebitz/Zotero/storage/PAG5GLA7/Rudolph et al. - 2023 - ChatGPT Bullshit spewer or the end of traditional.pdf}
}

@inproceedings{sarsa2022automatic,
  title = {Automatic {{Generation}} of {{Programming Exercises}} and {{Code Explanations Using Large Language Models}}},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{International Computing Education Research}} - {{Volume}} 1},
  author = {Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
  year = {2022},
  month = aug,
  series = {{{ICER}} '22},
  volume = {1},
  pages = {27--43},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3501385.3543957},
  urldate = {2023-09-05},
  abstract = {This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.},
  isbn = {978-1-4503-9194-8},
  keywords = {Automated feedback,Code explanations,CS1,Exercise generation,GPT-3,Large language models,Natural language generation,OpenAI Codex,Programming exercises,Resource generation,Robosourcing},
  file = {/Users/lschoebitz/Zotero/storage/SH6GAFPH/Sarsa et al. - 2022 - Automatic Generation of Programming Exercises and .pdf}
}

@incollection{sweller2011worked,
  title = {The {{Worked Example}} and {{Problem Completion Effects}}},
  booktitle = {Cognitive {{Load Theory}}},
  author = {Sweller, John and Ayres, Paul and Kalyuga, Slava},
  editor = {Sweller, John and Ayres, Paul and Kalyuga, Slava},
  year = {2011},
  series = {Explorations in the {{Learning Sciences}}, {{Instructional Systems}} and {{Performance Technologies}}},
  pages = {99--109},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4419-8126-4_8},
  urldate = {2023-09-05},
  abstract = {A worked example provides a step-by-step solution to a problem. The following is an example from algebra: Make a the subject of the equation, \$\$ (a+b)/\textbackslash text\{\}\textbackslash text\{\textbackslash hspace\{0.05em\}\}c=d\$\$},
  isbn = {978-1-4419-8126-4},
  langid = {english},
  keywords = {Cognitive Load,Cognitive Load Theory,Conventional Group,Work Memory Load,Work Memory Resource},
  file = {/Users/lschoebitz/Zotero/storage/BGBVQPMQ/Sweller et al. - 2011 - The Worked Example and Problem Completion Effects.pdf}
}

@misc{wang2023adapting,
  title = {Towards {{Adapting Computer Science Courses}} to {{AI Assistants}}' {{Capabilities}}},
  author = {Wang, Tianjia and {Vargas-Diaz}, Daniel and Brown, Chris and Chen, Yan},
  year = {2023},
  month = jun,
  number = {arXiv:2306.03289},
  eprint = {2306.03289},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-09-05},
  abstract = {The use of AI assistants, along with the challenges they present, has sparked significant debate within the community of computer science education. While these tools demonstrate the potential to support students' learning and instructors' teaching, they also raise concerns about enabling unethical uses by students. Previous research has suggested various strategies aimed at addressing these issues. However, they concentrate on the introductory programming courses and focus on one specific type of problem. The present research evaluated the performance of ChatGPT, a state-of-the-art AI assistant, at solving 187 problems spanning three distinct types that were collected from six undergraduate computer science. The selected courses covered different topics and targeted different program levels. We then explored methods to modify these problems to adapt them to ChatGPT's capabilities to reduce potential misuse by students. Finally, we conducted semi-structured interviews with 11 computer science instructors. The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement. The results revealed issues ranging from academic fairness to long-term impact on students' mental models. From our results, we derived design implications and recommended tools to help instructors design and create future course material that could more effectively adapt to AI assistants' capabilities.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/lschoebitz/Zotero/storage/67Q4HPVV/Wang et al. - 2023 - Towards Adapting Computer Science Courses to AI As.pdf;/Users/lschoebitz/Zotero/storage/9BZHBFZW/2306.html}
}

@misc{whata,
  title = {What Is {{AI Literacy}}? {{A Comprehensive Guide}} for {{Beginners}}},
  shorttitle = {What Is {{AI Literacy}}?},
  urldate = {2023-08-31},
  abstract = {Explore the importance of AI literacy in our AI-driven world. Understand its components, its role in education and business, and how to develop it within organizations.},
  howpublished = {https://www.datacamp.com/blog/what-is-ai-literacy-a-comprehensive-guide-for-beginners},
  langid = {american},
  file = {/Users/lschoebitz/Zotero/storage/XDYCLQT6/what-is-ai-literacy-a-comprehensive-guide-for-beginners.html}
}

@misc{wilson2019teaching,
  title = {Teaching {{Tech Together}}: {{How}} to {{Make Lessons That Work}} and {{Build}} a {{Teaching Community Around Them}}},
  shorttitle = {Teaching {{Tech Together}}},
  author = {Wilson, Greg},
  year = {2019},
  urldate = {2022-04-07},
  abstract = {Teaching Tech Together},
  howpublished = {Chapman \& Hall/CRC Press},
  isbn = {978-0-367-35297-4}
}
